// index.js

// 1) Imports
const express   = require('express');
const cors      = require('cors');
const multer    = require('multer');
const admin     = require('firebase-admin');
const canvas    = require('canvas');
const faceapi   = require('face-api.js');
const tf        = require('@tensorflow/tfjs');
require('@tensorflow/tfjs-backend-cpu');
const path      = require('path');

// â€” Inicializa Firebase â€”
admin.initializeApp({
  credential: admin.credential.cert(require('./serviceAccountKey.json')),
  storageBucket: 'crud-fdmv-2025.firebasestorage.app'
});
const db     = admin.firestore();
const bucket = admin.storage().bucket();

// â€” Monkey-patch canvas para face-api en Node â€”
const { Canvas, Image, ImageData } = canvas;
faceapi.env.monkeyPatch({ Canvas, Image, ImageData });

// 2) Express + middleware
const app    = express();
const upload = multer({ storage: multer.memoryStorage() });
app.use(cors());

// Array global para descriptores precargados
let knownFaces = [];

// 3) Ruta de reconocimiento facial
app.post('/upload', upload.single('image'), async (req, res) => {
  console.log('--- NUEVA PETICIÃ“N /upload ---');
  console.log('â–· Headers recibidos:', JSON.stringify(req.headers, null, 2));
  console.log('â–· Query params:', req.query);

  if (!req.file) {
    console.log('ğŸš« No se recibiÃ³ ningÃºn archivo en la peticiÃ³n');
    console.log('ğŸ”™ Respondiendo matches vacÃ­os');
    return res.json({ matches: [] });
  }

  console.log(`ğŸ“© Archivo recibido:
    fieldname    = ${req.file.fieldname}
    originalname = ${req.file.originalname}
    mimetype     = ${req.file.mimetype}
    size         = ${req.file.size} bytes
  `);

  try {
    console.log('ğŸ” Cargando imagen a canvasâ€¦');
    const uploadImg = await canvas.loadImage(req.file.buffer);

    console.log('ğŸ§  Detectando rostro en la imagen subidaâ€¦');
    const uploadDet = await faceapi
      .detectSingleFace(uploadImg)
      .withFaceLandmarks()
      .withFaceDescriptor();

    if (!uploadDet) {
      console.log('âš ï¸ No se detectÃ³ rostro en la imagen');
      console.log('ğŸ”™ Respondiendo matches vacÃ­os');
      return res.json({ matches: [] });
    }
    console.log('âœ”ï¸ Rostro detectado (descriptor length =', uploadDet.descriptor.length, ')');

    console.log(`ğŸ” Comparando con ${knownFaces.length} caras precargadasâ€¦`);
    let best = { name: null, distance: 1 };
    for (let face of knownFaces) {
      const d = faceapi.euclideanDistance(uploadDet.descriptor, face.descriptor);
      console.log(`    â€¢ ${face.name} â†’ distance = ${d.toFixed(3)}`);
      if (d < best.distance) best = { name: face.name, distance: d };
    }
    console.log(`ğŸ† Mejor match: ${best.name} (distance = ${best.distance.toFixed(3)})`);

    if (!best.name || best.distance > 0.6) {
      console.log('âŒ Ninguna coincidencia fiable (threshold = 0.6)');
      console.log('ğŸ”™ Respondiendo matches vacÃ­os');
      return res.json({ matches: [] });
    }

    console.log(`ğŸ“š Consultando Firestore doc "${best.name}"â€¦`);
    const doc = await db.collection('tbl_face1').doc(best.name).get();
    if (!doc.exists) {
      console.log(`âŒ Documento no encontrado para "${best.name}"`);
      console.log('ğŸ”™ Respondiendo matches vacÃ­os');
      return res.json({ matches: [] });
    }

    const data = doc.data();
    console.log('ğŸ“„ Datos recuperados de Firestore:', data);

    const match = {
      label:           data.label,
      fechaNacimiento: data.fechaNacimiento,
      tlfEmergencia:   data.tlfEmergencia,
      cedula:          data.cedula,
      imgUrl:          data.imgUrl,
      distance:        parseFloat(best.distance.toFixed(3))
    };

    const payload = { matches: [ match ] };
    console.log('ğŸ“¦ Payload de respuesta (JSON):\n', JSON.stringify(payload, null, 2));
    console.log('â¡ï¸ Enviando respuesta 200 OK');

    return res.json(payload);
  } catch (err) {
    console.error('ğŸ’¥ Error en /upload:', err);
    console.log('ğŸ”™ Respondiendo 500 con matches vacÃ­os');
    return res.status(500).json({ matches: [] });
  }
});

// 4) IIFE para cargar modelos y cara conocidas, luego arranca el servidor
;(async () => {
  console.log('ğŸ”„ Inicializando TensorFlow backend CPU...');
  await tf.setBackend('cpu');

  const MODEL_URL = 'https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights';
  console.log('ğŸ”„ Cargando modelos desde', MODEL_URL);
  await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);
  await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
  await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
  console.log('ğŸ§  Modelos cargados');

  console.log('ğŸ” Precargando caras conocidas de Firebase Storage...');
  const [files] = await bucket.getFiles({ prefix: 'img/' });

  for (let file of files) {
    const fullName = file.name.split('/').pop();
    const baseName = fullName.split('.').shift();
    console.log(`  â€¢ Procesando ${fullName}`);

    try {
      const [metadata] = await file.getMetadata();
      const contentType = metadata.contentType || '';
      if (!contentType.startsWith('image/')) {
        console.log(`    â­ Saltado (no es imagen): ${fullName} â€” ${contentType}`);
        continue;
      }

      const [buffer] = await file.download();
      console.log(`    ğŸ“¥ Descargado ${fullName} (${buffer.length} bytes)`);

      const img = await canvas.loadImage(buffer);
      const det = await faceapi
        .detectSingleFace(img)
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (det) {
        knownFaces.push({ name: baseName, descriptor: det.descriptor });
        console.log(`    âœ”ï¸ Cara detectada y precargada: ${baseName}`);
      } else {
        console.log(`    âš ï¸ No se detectÃ³ rostro en ${fullName}`);
      }
    } catch (e) {
      console.warn(`    âŒ Error procesando ${baseName}: ${e.message}`);
    }
  }

  console.log(`âœ… Precarga finalizada. Total knownFaces: ${knownFaces.length}`);

  app.listen(5000, () => console.log('ğŸš€ Server corriendo en http://localhost:5000'));
})();
